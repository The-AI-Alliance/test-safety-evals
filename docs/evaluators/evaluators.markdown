---
layout: default
title: Evaluators and Benchmarks
nav_order: 50
has_children: true
---

# Evaluators and Benchmarks

This section describes the evaluators that implement the evaluations identified in the [taxonomy]({{site.baseurl}}/taxonomy/taxonomy). Evaluations include some combination of code and data.

Benchmarks that aggregate evaluators for larger goals, e.g., domain-specific scenarios, are also cataloged here.

For now, see the [`unitxt` catalog](https://www.unitxt.ai/en/latest/catalog/catalog.__dir__.html){:target="unitxt-catalog"} for a set of evaluators implemented using [`unitxt`](https://www.unitxt.ai){:target="unitxt"}.

## Evaluators and Benchmarks to Explore

A list of possible candidates to incorporate in our catalog.

* NeurIPS 2024 [Datasets Benchmarks](https://neurips.cc/virtual/2024/events/datasets-benchmarks-2024)

_More Coming Soon_

